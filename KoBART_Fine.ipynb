{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ltqPg4UlQxP",
        "outputId": "2f899da9-13ac-43c3-8cf9-6e8ce591b306"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/seujung/KoBART-summarization.git\n",
        "!cd KoBART-summarization && ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-mq-KMVkzPY",
        "outputId": "ce238c59-5993-4181-ed22-8078f799c3cc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'KoBART-summarization'...\n",
            "remote: Enumerating objects: 155, done.\u001b[K\n",
            "remote: Counting objects: 100% (72/72), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 155 (delta 49), reused 44 (delta 40), pack-reused 83 (from 1)\u001b[K\n",
            "Receiving objects: 100% (155/155), 37.24 MiB | 38.05 MiB/s, done.\n",
            "Resolving deltas: 100% (79/79), done.\n",
            "data\t\t    get_model_binary.py  install_kobart.sh  README.md\t      run_train.sh\n",
            "dataset.py\t    imgs\t\t LICENSE\t    requirements.txt  train.py\n",
            "download_binary.py  infer.py\t\t model.py\t    rouge_metric.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install loguru\n",
        "!pip install lightning\n",
        "!pip install torchmetrics==0.6.0\n",
        "!pip install pytorch_lightning==1.5.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yynj5b62CEDP",
        "outputId": "fe280237-fa47-4798-83f9-8dbf63375a55"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting loguru\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: loguru\n",
            "Successfully installed loguru-0.7.3\n",
            "Collecting lightning\n",
            "  Downloading lightning-2.4.0-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.10/dist-packages (from lightning) (6.0.2)\n",
            "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (2024.10.0)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning)\n",
            "  Downloading lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (24.2)\n",
            "Requirement already satisfied: torch<4.0,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (2.5.1+cu121)\n",
            "Collecting torchmetrics<3.0,>=0.7.0 (from lightning)\n",
            "  Downloading torchmetrics-1.6.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.12.2)\n",
            "Collecting pytorch-lightning (from lightning)\n",
            "  Downloading pytorch_lightning-2.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (3.11.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning) (75.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=2.1.0->lightning) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch<4.0,>=2.1.0->lightning) (1.3.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics<3.0,>=0.7.0->lightning) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<4.0,>=2.1.0->lightning) (3.0.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (3.10)\n",
            "Downloading lightning-2.4.0-py3-none-any.whl (810 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m811.0/811.0 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
            "Downloading torchmetrics-1.6.0-py3-none-any.whl (926 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m926.4/926.4 kB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lightning-utilities, torchmetrics, pytorch-lightning, lightning\n",
            "Successfully installed lightning-2.4.0 lightning-utilities-0.11.9 pytorch-lightning-2.4.0 torchmetrics-1.6.0\n",
            "Collecting torchmetrics==0.6.0\n",
            "  Downloading torchmetrics-0.6.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from torchmetrics==0.6.0) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics==0.6.0) (2.5.1+cu121)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchmetrics==0.6.0) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.1->torchmetrics==0.6.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.1->torchmetrics==0.6.0) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.1->torchmetrics==0.6.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.1->torchmetrics==0.6.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.1->torchmetrics==0.6.0) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.1->torchmetrics==0.6.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.3.1->torchmetrics==0.6.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3.1->torchmetrics==0.6.0) (3.0.2)\n",
            "Downloading torchmetrics-0.6.0-py3-none-any.whl (329 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m329.4/329.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchmetrics\n",
            "  Attempting uninstall: torchmetrics\n",
            "    Found existing installation: torchmetrics 1.6.0\n",
            "    Uninstalling torchmetrics-1.6.0:\n",
            "      Successfully uninstalled torchmetrics-1.6.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lightning 2.4.0 requires torchmetrics<3.0,>=0.7.0, but you have torchmetrics 0.6.0 which is incompatible.\n",
            "pytorch-lightning 2.4.0 requires torchmetrics>=0.7.0, but you have torchmetrics 0.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torchmetrics-0.6.0\n",
            "Collecting pytorch_lightning==1.5.2\n",
            "  Downloading pytorch_lightning-1.5.2-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.5.2) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.5.2) (2.5.1+cu121)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.5.2) (1.0.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.5.2) (4.66.6)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.5.2) (6.0.2)\n",
            "Requirement already satisfied: fsspec!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.2) (2024.10.0)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.5.2) (2.17.1)\n",
            "Requirement already satisfied: torchmetrics>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.5.2) (0.6.0)\n",
            "Collecting pyDeprecate==0.3.1 (from pytorch_lightning==1.5.2)\n",
            "  Downloading pyDeprecate-0.3.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.5.2) (24.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.5.2) (4.12.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.2) (3.11.9)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.5.2) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.5.2) (1.68.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.5.2) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.5.2) (4.25.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.5.2) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.5.2) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.5.2) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.5.2) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->pytorch_lightning==1.5.2) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->pytorch_lightning==1.5.2) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->pytorch_lightning==1.5.2) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->pytorch_lightning==1.5.2) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.6->pytorch_lightning==1.5.2) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.2) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.2) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.2) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.2) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.2) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.2) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.2) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.2) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.2.0->pytorch_lightning==1.5.2) (3.0.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.2) (3.10)\n",
            "Downloading pytorch_lightning-1.5.2-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: pyDeprecate, pytorch_lightning\n",
            "  Attempting uninstall: pytorch_lightning\n",
            "    Found existing installation: pytorch-lightning 2.4.0\n",
            "    Uninstalling pytorch-lightning-2.4.0:\n",
            "      Successfully uninstalled pytorch-lightning-2.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lightning 2.4.0 requires torchmetrics<3.0,>=0.7.0, but you have torchmetrics 0.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pyDeprecate-0.3.1 pytorch_lightning-1.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# 현재 작업 디렉토리 확인\n",
        "print(os.getcwd())\n",
        "\n",
        "# 디렉토리 변경\n",
        "os.chdir(\"/content/KoBART-summarization\")\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9DRqNatlQZI",
        "outputId": "cb98caf2-071e-4bdb-855f-6ff43710890e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/KoBART-summarization\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import csv\n",
        "\n",
        "# JSON 파일 로드\n",
        "with open(\"/content/sample_data/naver_news_cleaned (2).json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# TSV 파일로 저장\n",
        "with open(\"train.tsv\", \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
        "    tsv_writer = csv.writer(f, delimiter=\"\\t\")\n",
        "    # 헤더 작성\n",
        "    tsv_writer.writerow([\"text\", \"keywords\"])\n",
        "    # 데이터 작성\n",
        "    for item in data:\n",
        "        tsv_writer.writerow([item[\"text\"], \" \".join(item[\"keywords\"])])"
      ],
      "metadata": {
        "id": "FFswKoUGAQ85"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv train.tsv data/"
      ],
      "metadata": {
        "id": "4VKWlI65AeGq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls data/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_pvU_6PEEz0",
        "outputId": "cb8aac6e-f8f5-4c0e-dd81-8541ce2e0053"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test.tar.gz  train.tar.gz  train.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp data/train.tsv data/test.tsv"
      ],
      "metadata": {
        "id": "XvE00nnkExix"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# train.tsv 불러오기\n",
        "train_data = pd.read_csv(\"data/train.tsv\", sep=\"\\t\")\n",
        "\n",
        "# 80%는 train, 20%는 test로 분리\n",
        "train_split = train_data.sample(frac=0.8, random_state=42)\n",
        "test_split = train_data.drop(train_split.index)\n",
        "\n",
        "# 분리된 데이터를 저장\n",
        "train_split.to_csv(\"data/train.tsv\", sep=\"\\t\", index=False)\n",
        "test_split.to_csv(\"data/test.tsv\", sep=\"\\t\", index=False)"
      ],
      "metadata": {
        "id": "SzeMuWDvE2H1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# train.tsv 헤더 수정\n",
        "train_data = pd.read_csv(\"data/train.tsv\", sep=\"\\t\")\n",
        "train_data.rename(columns={\"text\": \"news\"}, inplace=True)\n",
        "train_data.to_csv(\"data/train.tsv\", sep=\"\\t\", index=False)\n",
        "\n",
        "# test.tsv 헤더 수정\n",
        "test_data = pd.read_csv(\"data/test.tsv\", sep=\"\\t\")\n",
        "test_data.rename(columns={\"text\": \"news\"}, inplace=True)\n",
        "test_data.to_csv(\"data/test.tsv\", sep=\"\\t\", index=False)"
      ],
      "metadata": {
        "id": "_01egVj6J_Yg"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# train.tsv 수정\n",
        "train_data = pd.read_csv(\"data/train.tsv\", sep=\"\\t\")\n",
        "train_data.rename(columns={\"keywords\": \"summary\"}, inplace=True)\n",
        "train_data.to_csv(\"data/train.tsv\", sep=\"\\t\", index=False)\n",
        "\n",
        "# test.tsv 수정\n",
        "test_data = pd.read_csv(\"data/test.tsv\", sep=\"\\t\")\n",
        "test_data.rename(columns={\"keywords\": \"summary\"}, inplace=True)\n",
        "test_data.to_csv(\"data/test.tsv\", sep=\"\\t\", index=False)"
      ],
      "metadata": {
        "id": "KcTDaPO6E891"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 데이터 로드\n",
        "train_data = pd.read_csv(\"data/train.tsv\", sep=\"\\t\")\n",
        "test_data = pd.read_csv(\"data/test.tsv\", sep=\"\\t\")\n",
        "\n",
        "# 데이터 검증\n",
        "print(\"Train 데이터 Null 값:\", train_data.isnull().sum())\n",
        "print(\"Test 데이터 Null 값:\", test_data.isnull().sum())\n",
        "\n",
        "# Null 값 제거\n",
        "train_data = train_data.dropna()\n",
        "test_data = test_data.dropna()\n",
        "\n",
        "# 수정된 데이터 저장\n",
        "train_data.to_csv(\"data/train.tsv\", sep=\"\\t\", index=False)\n",
        "test_data.to_csv(\"data/test.tsv\", sep=\"\\t\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRH3A_QgL2NW",
        "outputId": "180d9c1b-08e7-459f-8d71-eade2365a3c0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train 데이터 Null 값: news       0\n",
            "summary    1\n",
            "dtype: int64\n",
            "Test 데이터 Null 값: news       0\n",
            "summary    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!WANDB_MODE=disabled python train.py \\\n",
        "    --train_file data/train.tsv \\\n",
        "    --test_file data/test.tsv \\\n",
        "    --batch_size 16 \\\n",
        "    --max_epochs 5 \\\n",
        "    --gradient_clip_val 1.0 \\\n",
        "    --num_workers 4 \\\n",
        "    --accelerator gpu \\\n",
        "    --num_gpus 1 \\\n",
        "    --lr 3e-5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9ddRPvkBnXi",
        "outputId": "bfcd2b89-2cc6-4e74-fb3d-937f875281ad"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-09 12:22:28.396233: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-09 12:22:28.419950: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-09 12:22:28.427368: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-09 12:22:28.445574: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-09 12:22:30.601026: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "tokenizer.json: 100% 682k/682k [00:00<00:00, 12.0MB/s]\n",
            "added_tokens.json: 100% 4.00/4.00 [00:00<00:00, 19.3kB/s]\n",
            "special_tokens_map.json: 100% 111/111 [00:00<00:00, 605kB/s]\n",
            "config.json: 100% 1.36k/1.36k [00:00<00:00, 7.40MB/s]\n",
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
            "\u001b[32m2024-12-09 12:22:34.122\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mNamespace(train_file='data/train.tsv', test_file='data/test.tsv', batch_size=16, checkpoint='checkpoint', max_len=512, max_epochs=5, lr=3e-05, accelerator='gpu', num_gpus=1, gradient_clip_val=1.0, num_workers=4)\u001b[0m\n",
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
            "model.safetensors: 100% 495M/495M [00:05<00:00, 86.5MB/s]\n",
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/KoBART-summarization/train.py\", line 96, in <module>\n",
            "    trainer = L.Trainer(max_epochs=args.max_epochs,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/utilities/argparse.py\", line 70, in insert_env_defaults\n",
            "    return fn(self, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\", line 395, in __init__\n",
            "    self._accelerator_connector = _AcceleratorConnector(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/connectors/accelerator_connector.py\", line 143, in __init__\n",
            "    self._accelerator_flag = self._choose_gpu_accelerator_backend()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/connectors/accelerator_connector.py\", line 353, in _choose_gpu_accelerator_backend\n",
            "    raise MisconfigurationException(\"No supported gpu backend found!\")\n",
            "lightning.fabric.utilities.exceptions.MisconfigurationException: No supported gpu backend found!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import PreTrainedTokenizerFast, BartForConditionalGeneration\n",
        "import torch\n",
        "\n",
        "# KoBART 모델 및 토크나이저 로드\n",
        "checkpoint_path = \"/content/KoBART-summarization/checkpoint/model_chp/epoch=04-val_loss=0.882.ckpt\"\n",
        "model = BartForConditionalGeneration.from_pretrained(\"hyunwoongko/kobart\")\n",
        "checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n",
        "model.load_state_dict(checkpoint[\"state_dict\"], strict=False)\n",
        "\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"hyunwoongko/kobart\")\n",
        "\n",
        "# 테스트 문장 요약\n",
        "test_text = \"\"\"\n",
        "유방암 재발 걱정인데 HER2 세분화 연구로 더 정밀하게 예측 강남세브란스 연구팀 발표\n",
        "유방암 환자 2천여명 분석 HER2 저발현 그룹이 음성보다 재발 확률 높아 유방암은 환자가\n",
        "지닌 인자 유무에 따라 여러 아형으로 분류된다 전통적으로는 호르몬 수용체를 갖고 있는지에\n",
        "따라 양성과 음성으로 나눈 뒤 그 안에서 HER2 단백질이 있는지 없는지 살폈다 HER2란\n",
        "인간 표피 성장 인자 수용체 2형 단백질로 암세포 표면에 HER2가 무한 증식을 일으키면\n",
        "문제가 될 수 있다 최근에는 호르몬 수용체를 지녔지만 HER2 단백질이 없는 그룹을 보다\n",
        "세부적으로 분류하는 추세다 HER2 저발현 그룹 HER2Low과 HER2 음성 HER2zero으로 나누는\n",
        "것이 대표적이다...\n",
        "\"\"\"\n",
        "\n",
        "# 입력 토큰 변환\n",
        "inputs = tokenizer(test_text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "\n",
        "# 요약 생성\n",
        "summary_ids = model.generate(\n",
        "    inputs[\"input_ids\"],\n",
        "    max_length=10,  # 최대 10글자\n",
        "    min_length=10,  # 최소 10글자\n",
        "    num_beams=6,    # 빔 서치 강화\n",
        "    no_repeat_ngram_size=3,  # 반복 방지\n",
        "    length_penalty=1.5,  # 요약 길이 강화\n",
        "    early_stopping=True\n",
        ")\n",
        "\n",
        "# 요약 디코딩\n",
        "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "print(\"10글자 요약:\", summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3nQlC_XTeAE",
        "outputId": "3a63f941-80bc-42b1-d723-c535e0da1792"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
            "<ipython-input-31-b65b5bbb6049>:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10글자 요약: \n",
            " \n",
            " \n",
            "유방암 재발 걱정\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import PreTrainedTokenizerFast, BartForConditionalGeneration\n",
        "import torch\n",
        "\n",
        "# 모델 저장 경로\n",
        "model_save_path = \"/content/kobart_finetuned\"\n",
        "\n",
        "# 학습한 모델 로드 (이미 학습했다고 가정)\n",
        "checkpoint_path = \"/content/KoBART-summarization/checkpoint/model_chp/epoch=04-val_loss=0.882.ckpt\"\n",
        "model = BartForConditionalGeneration.from_pretrained(\"hyunwoongko/kobart\")\n",
        "checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n",
        "model.load_state_dict(checkpoint[\"state_dict\"], strict=False)\n",
        "\n",
        "# 토크나이저 로드\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"hyunwoongko/kobart\")\n",
        "\n",
        "# 모델과 토크나이저 저장\n",
        "model.save_pretrained(model_save_path)\n",
        "tokenizer.save_pretrained(model_save_path)\n",
        "\n",
        "print(f\"Model and tokenizer saved to {model_save_path}\")"
      ],
      "metadata": {
        "id": "IKA3pOiPYEiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DaaUMZvyYZCs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}